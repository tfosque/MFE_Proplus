"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.createLocalFileSourceProvider = void 0;
const zlib_1 = __importDefault(require("zlib"));
const path_1 = __importDefault(require("path"));
const stream_1 = require("stream");
const fs_extra_1 = __importDefault(require("fs-extra"));
const tar_1 = __importDefault(require("tar"));
const fp_1 = require("lodash/fp");
const stream_chain_1 = require("stream-chain");
const Parser_1 = require("stream-json/jsonl/Parser");
const encryption_1 = require("../../../utils/encryption");
const stream_2 = require("../../../utils/stream");
const providers_1 = require("../../../errors/providers");
const utils_1 = require("./utils");
/**
 * Constant for the metadata file path
 */
const METADATA_FILE_PATH = 'metadata.json';
const createLocalFileSourceProvider = (options) => {
    return new LocalFileSourceProvider(options);
};
exports.createLocalFileSourceProvider = createLocalFileSourceProvider;
class LocalFileSourceProvider {
    type = 'source';
    name = 'source::local-file';
    options;
    #metadata;
    constructor(options) {
        this.options = options;
        const { encryption } = this.options;
        if (encryption.enabled && encryption.key === undefined) {
            throw new Error('Missing encryption key');
        }
    }
    /**
     * Pre flight checks regarding the provided options, making sure that the file can be opened (decrypted, decompressed), etc.
     */
    async bootstrap() {
        const { path: filePath } = this.options.file;
        try {
            // Read the metadata to ensure the file can be parsed
            await this.#loadMetadata();
            // TODO: we might also need to read the schema.jsonl files & implements a custom stream-check
        }
        catch (e) {
            if (this.options?.encryption?.enabled) {
                throw new providers_1.ProviderInitializationError(`Key is incorrect or the file '${filePath}' is not a valid Strapi data file.`);
            }
            throw new providers_1.ProviderInitializationError(`File '${filePath}' is not a valid Strapi data file.`);
        }
        if (!this.#metadata) {
            throw new providers_1.ProviderInitializationError('Could not load metadata from Strapi data file.');
        }
    }
    async #loadMetadata() {
        const backupStream = this.#getBackupStream();
        this.#metadata = await this.#parseJSONFile(backupStream, METADATA_FILE_PATH);
    }
    async #loadAssetMetadata(path) {
        const backupStream = this.#getBackupStream();
        return this.#parseJSONFile(backupStream, path);
    }
    async getMetadata() {
        if (!this.#metadata) {
            await this.#loadMetadata();
        }
        return this.#metadata ?? null;
    }
    async getSchemas() {
        const schemas = await (0, stream_2.collect)(this.createSchemasReadStream());
        if ((0, fp_1.isEmpty)(schemas)) {
            throw new providers_1.ProviderInitializationError('Could not load schemas from Strapi data file.');
        }
        return (0, fp_1.keyBy)('uid', schemas);
    }
    createEntitiesReadStream() {
        return this.#streamJsonlDirectory('entities');
    }
    createSchemasReadStream() {
        return this.#streamJsonlDirectory('schemas');
    }
    createLinksReadStream() {
        return this.#streamJsonlDirectory('links');
    }
    createConfigurationReadStream() {
        // NOTE: TBD
        return this.#streamJsonlDirectory('configuration');
    }
    createAssetsReadStream() {
        const inStream = this.#getBackupStream();
        const outStream = new stream_1.PassThrough({ objectMode: true });
        const loadAssetMetadata = this.#loadAssetMetadata.bind(this);
        (0, stream_1.pipeline)([
            inStream,
            new tar_1.default.Parse({
                // find only files in the assets/uploads folder
                filter(filePath, entry) {
                    if (entry.type !== 'File') {
                        return false;
                    }
                    return (0, utils_1.isFilePathInDirname)('assets/uploads', filePath);
                },
                async onentry(entry) {
                    const { path: filePath, size = 0 } = entry;
                    const normalizedPath = (0, utils_1.unknownPathToPosix)(filePath);
                    const file = path_1.default.basename(normalizedPath);
                    let metadata;
                    try {
                        metadata = await loadAssetMetadata(`assets/metadata/${file}.json`);
                    }
                    catch (error) {
                        console.warn(` Failed to read metadata for ${file}, Strapi will try to fix this issue automatically`);
                    }
                    const asset = {
                        metadata,
                        filename: file,
                        filepath: normalizedPath,
                        stats: { size },
                        stream: entry,
                    };
                    outStream.write(asset);
                },
            }),
        ], () => outStream.end());
        return outStream;
    }
    #getBackupStream() {
        const { file, encryption, compression } = this.options;
        const streams = [];
        try {
            streams.push(fs_extra_1.default.createReadStream(file.path));
        }
        catch (e) {
            throw new Error(`Could not read backup file path provided at "${this.options.file.path}"`);
        }
        if (encryption.enabled && encryption.key) {
            streams.push((0, encryption_1.createDecryptionCipher)(encryption.key));
        }
        if (compression.enabled) {
            streams.push(zlib_1.default.createGunzip());
        }
        return (0, stream_chain_1.chain)(streams);
    }
    // `directory` must be posix formatted path
    #streamJsonlDirectory(directory) {
        const inStream = this.#getBackupStream();
        const outStream = new stream_1.PassThrough({ objectMode: true });
        (0, stream_1.pipeline)([
            inStream,
            new tar_1.default.Parse({
                filter(filePath, entry) {
                    if (entry.type !== 'File') {
                        return false;
                    }
                    return (0, utils_1.isFilePathInDirname)(directory, filePath);
                },
                async onentry(entry) {
                    const transforms = [
                        // JSONL parser to read the data chunks one by one (line by line)
                        (0, Parser_1.parser)({
                            checkErrors: true,
                        }),
                        // The JSONL parser returns each line as key/value
                        (line) => line.value,
                    ];
                    const stream = entry.pipe((0, stream_chain_1.chain)(transforms));
                    try {
                        for await (const chunk of stream) {
                            outStream.write(chunk);
                        }
                    }
                    catch (e) {
                        outStream.destroy(new providers_1.ProviderTransferError(`Error parsing backup files from backup file ${entry.path}: ${e.message}`, {
                            details: {
                                error: e,
                            },
                        }));
                    }
                },
            }),
        ], async () => {
            // Manually send the 'end' event to the out stream
            // once every entry has finished streaming its content
            outStream.end();
        });
        return outStream;
    }
    // For collecting an entire JSON file then parsing it, not for streaming JSONL
    async #parseJSONFile(fileStream, filePath) {
        return new Promise((resolve, reject) => {
            (0, stream_1.pipeline)([
                fileStream,
                // Custom backup archive parsing
                new tar_1.default.Parse({
                    /**
                     * Filter the parsed entries to only keep the one that matches the given filepath
                     */
                    filter(entryPath, entry) {
                        if (entry.type !== 'File') {
                            return false;
                        }
                        return (0, utils_1.isPathEquivalent)(entryPath, filePath);
                    },
                    async onentry(entry) {
                        // Collect all the content of the entry file
                        const content = await entry.collect();
                        try {
                            // Parse from buffer array to string to JSON
                            const parsedContent = JSON.parse(Buffer.concat(content).toString());
                            // Resolve the Promise with the parsed content
                            resolve(parsedContent);
                        }
                        catch (e) {
                            reject(e);
                        }
                        finally {
                            // Cleanup (close the stream associated to the entry)
                            entry.destroy();
                        }
                    },
                }),
            ], () => {
                // If the promise hasn't been resolved and we've parsed all
                // the archive entries, then the file doesn't exist
                reject(new Error(`File "${filePath}" not found`));
            });
        });
    }
}
//# sourceMappingURL=index.js.map